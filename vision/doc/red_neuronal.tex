\chapter{Módulo de red neuronal}
\label{red_neuronal} 

\section{Introducción}
Las Redes Neuronales Artificiales (ANNs de Artificial Neural Networks) fueron originalmente una simulación abstracta de los sistemas nerviosos biológicos, formados por un conjunto de unidades llamadas neuronas o nodos conectadas unas con otras. Estas conexiones tienen una gran semejanza con las dendritas y los axones en los sistemas nerviosos biológicos. 

\bigskip 
Una ANN es un gran numero de conmutadores interconectados, donde a las conexiones se les asigna un peso. Este peso será fijado durante la fase de aprendizaje. El procesamiento de información es paralelo distribuido.

\bigskip 
En que tipos de problemas se utilizan:
\begin{itemize}
\item En problemas donde los ejemplos se describen con un gran numero de atributos.
\item Puede haber ruido en los datos.
\item Cuando no se conoce la forma de la función objetivo. Problemas que no tienen un algoritmo especifico para su solución, o cuyo algoritmo es demasiado complejo para ser encontrado. 
\item Cuando es permisible un tiempo de entrenamiento largo.
\item Ejemplos: Reconocimiento del habla, clasificación de imágenes, predicciones financieras, etc.
\end{itemize} 

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.4,bb=0 0 406 203]{red1.png}
  \caption{ Ejemplo esquemático de una ANN.}
\end{figure}

\bigskip 
Dicho esto la elección de una red neuronal como medio de resolución del problema de reconocimiento de patrones sería en este caso la más acertada. Es muy útil cuando no se conoce la función objetivo y se estima que los datos de entrada llegan con cierto porcentaje de ruido. La decisión se tomó meses antes de empezar el proyecto. Para asegurarnos de que era viable implementamos la red dentro de un pequeño programa, que a partir de imágenes de entrada devolvía cierto si detectaba una imagen de una persona con una guante blanco y falso si no había guante.

\section{Descripción técnica}
Hemos utilizado una red multicapa, ya que permiten representar superficies de decisión no lineales. Debido a esto no se puede utilizar unidades lineales ya que solo permitirían representar funciones lineales. Tampoco pudimos utilizar perceptrones porque su función de salida es discontinua, no derivable y por lo tanto no se le puede aplicar el descenso del gradiente. Necesitábamos una unidad que diese como salida una función no lineal y que fuese derivable con respecto a las entradas.

\bigskip 
Por eso utilizamos el sigmoide como unidad.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.5,bb=0 0 378 120]{red2.png}
  \caption{ Unidad Sigmoide.}
\end{figure}

La función sigma  $ \sigma(x)  = \frac{1}{(1+e^{-x})} $ es no lineal y derivable $ \frac{d\sigma(x)}{dx} =  \sigma(x) . (1 - \sigma(x)) $.

El descenso de gradiente se puede utilizar para entrenar:
\begin{itemize}
\item Una unidad sigmoide.
\item Una red multicapa de unidades sigmoides. Retropropagación.
\end{itemize} 

La retropropagación permite aprender los pesos para una red multicapa con un numero de unidades e interconexiones dado. Consideramos una red con múltiples unidades de salida, de forma que el error es la suma de los errores sobre todas las salidas. El espacio de hipótesis viene dado por los valores posibles para los pesos de todas las unidades de red. Utilizamos el descenso de gradiente para encontrar una hipótesis que minimice el error, el descenso utilizado es incremental, es decir, los pesos se actualizan después de considerar cada ejemplo de entrenamiento en lugar de esperar a considerarlos todos. Es mas improbable que el descenso incremental caiga en un mínimo local.
\bigskip 

La secuencia de pasos utilizada en nuestro entrenamiento viene a ser esta:
\begin{itemize}
\item Crear la red. 
\item Se inicializan los pesos de la red con valores pequeños y aleatorios entre -0.05 y 0.05
\item Para una media de 30 iteraciones se realiza lo siguiente: De una lista de imágenes de entrenamiento se va cogiendo una a una y se cargan en la capa de entrada de la red, para esa imagen se calculan las capas, luego según un objetivo se calculo el error cometido en la capa oculta y en la salida y respecto a estos errores se reajustan los pesos de las interconexiones.
\item Se realiza un prueba y una validación con imágenes distintas a las del entrenamiento, para ver el porcentaje de error total cometido, si es aceptable se guarda en un archivo los pesos de la red entrenada, para que en la fase de reconocimiento de imágenes solo haya que realizar el calculo de capas.
\end{itemize} 	

Para cada unidad de salida k, se calcula su termino de error: $ \delta_{k} = O_{k} . (1 - O_{k}) . (t_{k} - O_{k}) $

Para cada unidad oculta h, se calcula su termino de error: $ \delta_{h} = O_{h} . (1 - O_{h}) . \Sigma (W_{kh} . \delta_{k}) $ , siendo k las salidas.

Se actualiza cada peso de la red $ W_{ji} = W_{ji} + \Delta (W_{ji}) $ donde $ \Delta (w_{ji}) = \eta .\delta_{j} .x_{ji} + \alpha .\Delta w_{ji}. (n-1) $. 

($ t_{k} $ es la salida dada por ejemplo de entrenamiento para la unidad k. $ o_{t} $ es la salida generada por la red.)

La actualización de los pesos en la iteración n depende de la actualización en n-1. El 2º termino de la ecuación representa la cantidad de movimiento. Un símil físico seria una pelota que cae por la superficie de error, la cantidad de movimiento hace que la pelota tienda a mantener la misma dirección, con esto se intenta evitar que la pelota pare en un mínimo local o que se pare en un llano.

\bigskip 
Respecto el descenso del gradiente en el sigmoide:
Para el descenso incremental consideramos el cambio en los pesos inducido por cada ejemplo de entrenamiento $ \Delta w_{ji} = \eta \frac{\eta E_{d}}{\eta w_{ji}} $ donde el error sobre un ejemplo de entrenamiento viene dado por la suma de los errores en cada unidad de salida $ E_{d}(w) \equiv \frac{1}{2} . \Sigma (t_{k} - o_{k})^{2} $ , siendo k las salidas

La salida viene dada por $ net = \Sigma w_{i}.x_{i} $ , i=0..n y $ o = \sigma (net) = \frac{1}{1 + e^{-net}} $, aplicando la regla de la cadena $ \frac{\eta E_{d}}{\eta w_{ji}} = \frac{\eta E_{d}}{\eta net_{j}} . \frac{\eta net_{j}}{\eta w_{ji}} = \frac{\eta E_{d}}{\eta net_{j}} . x_{ji} $. Para calcular $ \frac{\eta E_{d}}{\eta net_{j}} $ distinguimos el caso de las unidades de salida y las ocultas.

Error en las unidades de salida $ \frac{\eta E_{d}}{\eta net_{j}} = -(t_{j} - o_{j}). o_{j} .(1 - o_{j}) $. Error en la unidades ocultas $ \frac{\eta E_{d}}{\eta net_{j}} = o_{j} . (1 - o_{j}) . \Sigma (-\delta_{k} . w_{kj})  $.

\bigskip 
Para valores pequeños de los pesos (al principio del proceso) la red presenta una función casi lineal donde es menos probable encontrar mínimos locales. Cuando la función es mas compleja (un punto mas avanzado del proceso) es de esperar que nos hayamos acercado tanto al mínimo global que los mínimo locales sean aceptables. Para garantizar que alcanzamos el mínimo global utilizamos heurísticas:
\begin{itemize}
\item Añadiendo cantidad de movimiento.
\item Utilizando descenso incremental.
\item Entrenar distintas redes con los mismos ejemplos, pero con distintos valores iniciales en los pesos.
\end{itemize} 

La capacidad expresiva de este tipo de red es bastante alta ya que:
\begin{itemize}
\item Cualquier función booleana se puede representar con una red de dos capas.
\item Cualquier función continua se puede aproximar con un error arbitrariamente pequeño por una red de dos capas.
\item Cualquier función se puede aproximar con un error arbitrariamente pequeño por una red de tres capas (las dos ocultas de sigmoides y la de salida de unidades lineales).
\end{itemize} 

\section{Diseño}
Esta formada por una capa de entrada, una de salida y una sola capa oculta.
Si imaginásemos la red como una caja negra, esta tendría que recibir como entrada una imagen y sacar como salida una cadena de texto explicativa de algún atributo de esa imagen.

\bigskip 
En nuestro caso la entrada serán siempre imágenes del mismo tamaño 320x240 píxeles, por ello la capa de entrada consta de 76800 unidades. En realidad la entrada es un unsigned char* que representa la imagen con valores de 255 o 0, es decir, blanco o negro, recuerdo que las imágenes que le llegan a la red son imágenes que previamente han pasado por el modulo de filtro a si que llegan ya binarizadas. Estas entradas serán normalizadas entre 1 y 0, para que las entradas estén en el mismo rango que las unidades de la capa oculta y de salida.

\bigskip 
La capa oculta debe tener tan pocas unidades como sea posible. Medidas experimentales demuestran que el hecho de aumentar el número de  unidades ocultas proporciona mejoras poco significativas en la precisión, pero requieren mucho mas tiempo de entrenamiento. Nosotros hemos optado por utilizar 15 unidades.

\bigskip 
Como ya sabemos al robot se le controla con 2 manos, los gestos de la mano izquierda le indican las ordenes y los de las derecha los parámetros, con el objetivo de simplificar el diseño los gestos de ordenes y de parámetros son los mismos, pero significan cosas distintas. Tanto para ordenes como para parámetros hay 5 tipos de gestos. Como recordatorio las ordenes eran: parar, avanzar, girar a la izquierda y girar a la derecha. Y los parámetros eran nula, medio baja, medio alta, alta si la orden actual es la de avanzar, donde los parámetros indican la velocidad a la que debe hacerlo o 0º, 45º, 90º, 180º si la orden actual es una de giro. La 5º gesto tanto para ordenes como para parámetros es el ``gesto no reconocido''. Por tanto dado que hay 5 tipos de gestos ha reconocer, la red tendrá que sacar 5 posibles salidas. Al principio optamos por una capa de salida de una sola unidad. El valor oscila entre 0 y 1 así que por ejemplo si esta unidad valía 0.2 significaba que había reconocido el 2º gesto, si valía 0.8 había reconocido el 4º gesto. Luego se cambio al diseño actual que es una capa de salida de 5 unidades, esto hace a la red mucho mas fiable, se podía decir que la salida de la red antes era analógica y ahora es digital, ya que todas las salidas tendrán valores menores de 0.5 excepto una que será mayor, solo hay que asociar la unidad de la salida que se ha puesto en alta con una cadena de texto. Esta asociación se hace mediante un script en Lua, así es más modificable ya que si se quiere cambiar el texto de salida no hay que recompilar el proyecto, solo cambiar un archivo de texto.

\bigskip 
La organización de red por capas es estándar, la salida de cada unidad alimenta a todas las unidades de la siguiente capa.

La tasa de aprendizaje utilizada ha sido 0.3. La mas alta posible para reducir el tiempo de aprendizaje sin disminuir la precisión.

El descenso de gradiente es incremental para reducir el riesgo de quedarnos en mínimos locales.

Los pesos de la unidades de salida y oculta son inicializados con pequeños valores aleatorios entre 0.05 y -0.05.

\section{Entrenamiento}
La mayor parte del código utilizado en la red esta dirigido al entrenamiento. Por eso decidimos hacer un programa aparte que contiene el código de entrenamiento de la red y luego el código que está presente en el proyecto que solo contiene el necesario para crear una red, calcular los valores de las capas a partir del valor de la capa de entrada y generar la cadena de texto de salida. Así el código del proyecto queda mas sencillo para leer.

\bigskip 
El proceso de entrenamiento empieza con la sesión fotográfica, es necesario hacer mas de un centenar de fotos para obtener un entrenamiento medianamente fiable. Nosotros para el entrenamiento de ordenes sacamos 185 fotos, consiste en sacar fotos dándole ordenes al robot correctas, erróneas o simplemente no dándoselas. Todas estas fotos han de ser filtradas del mismo modo que lo haría el modulo de filtro del proyecto, la razón de hacer un filtrado previo es poder pasar a la red imágenes muy simples, también deben de ser tomadas en unas condiciones de iluminación similares a las que tendrá el entorno por el que circule el robot. No es lo mismo hacer aprender a la red a reconocer un gesto perdido en un mar de píxeles de miles de colores a reconocer un conjunto de píxeles blancos centrados sobre un fondo negro. Los objetivos mas perseguidos en este proyecto es la eficiencia y en este caso la fiabilidad en el reconocimiento.

\bigskip 
Las fotos son nombradas con un formato determinado, por ejemplo, ``\_orden\_parada\_21.bmp'' esto significa que la foto contiene la orden de parada y ``\_no\_gesto\_51.bmp'' indica que la foto no representa ninguna orden para el robot. Este formato es utilizado en el entrenamiento para que la red sepa ir reajustando los pesos según el nombre explicativo de la foto.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.5,bb=0 0 160 120]{_no_gesto_36.png}
  \caption{ \_no\_gesto\_36.png}
\end{figure}

Todas las fotos no son utilizadas para el entrenamiento. Se hacen 3 listas de fotos que se utilizaran para el entrenamiento, la prueba y la validación. Estas 2 ultimas sirven  para comprobar el buen funcionamiento de la red entrenada.

El objetivo del programa de entrenamiento es crear una red, entrenarla y salvar la estructura y pesos de red en un archivo.

El entrenamiento consiste en :
\begin{itemize}
\item Recorrer la lista de imágenes de entrenamiento una por una.
\item Cargar la imagen en la imagen en la capa de entrada, cada valor de píxel se asocia a una unidad de la capa.
\item Según el nombre de la foto, ejemplo ``\_orden\_parada\_21.bmp'', se cambia el objetivo, esto sirve para calcular el error cometido.
\item Cambiado el objetivo, se calcula el valor de la capas respecto a la capa de entrada, se calcula el error cometido en las capas oculta y salida y se reajustan los pesos, para disminuir el error.
\item Esta lista es recorrida un numero finito de iteraciones. Las condiciones de parada pueden ser varias. La nuestra es simplemente un numero concreto, en este caso fueron 30 iteraciones. Por tanto los pesos fueron ajustados 30x(numero de fotos de la lista) veces.
\end{itemize}
Ya tendríamos así unos pesos que representan una aproximación a la función buscada.
\bigskip 

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.4,bb=0 0 340 296]{prog_train.png}
  \caption{ Captura de nuestro programa de entrenamiento de redes.}
\end{figure}

\bigskip 
Estos fueron datos de un entrenamiento de la red:
\begin{itemize}
\item Datos entrada:
\begin{itemize}
\item 148 fotos de entrenamiento, 49 fotos de validación y 30 de prueba.
\item Índice de aprendizaje: 0.3
\item 20 iteraciones
\end{itemize} 
\item Datos salida:
\begin{itemize}
\item Porcentaje de aciertos en entrenamiento: 89   Error medio: 0,0141046521582562
\item Porcentaje de aciertos en validación: 93    Error medio: 0,00799933215976971
\item Porcentaje de aciertos en prueba: 100     Error medio: 0,00645778571591585
\end{itemize} 
\end{itemize}   

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.4,bb=0 0 504 231]{Grafica_Aciertos.png}
  \includegraphics[scale=0.4,bb=0 0 491 237]{Grafica_Errores.png}
  \caption{ La imagen de la izquierda muestra como aumenta el aprendizaje cuanto mas se enseña a la red. Aumentando el nº de aciertos. Y la de la derecha muestra como a medida que aprende comete menos errores reconociendo figuras.}
\end{figure}

\section{Red Neuronal en el proyecto}
Como cada modulo del pipeline, el modulo de red tiene un pequeño numero de funciones fijas utilizadas para ser llamadas desde el pipeline. Tres de ellas son ``red\_iniciar'', ``red\_cerrar'' y ``red\_ciclo''. Iniciar crea la red y carga el archivo creado por el programa de entrenamiento, por ejemplo el ``orden\_net''. La función cerrar libera toda la memoria. Y la función ciclo lo único que hace es recibir un char* que representa la imagen, cargar estos valores normalizados en la capa de entrada y calcular el valor de las capas oculta y de salida según los pesos, que solamente tarda aproximadamente 0.10 segundos. Luego como ya dijimos solamente una de las cinco unidades de la capa de salida tendrá un valor superior a 0.5, esto es equivalente a que se ha puesto en ALTA y el modulo sacará como salida la cadena de texto asociada a esa unidad. Cadena modificable desde un script junto con el nombre del archivo de la red entrenada. Todo lo que sea modificable en un futuro por posibles mejoras son parámetros que van escritos en scripts.

\bigskip 
Estas son 5 imágenes filtradas de ejemplo, cada una representa una orden o un parámetro.

Recordatorio:
\begin{itemize}
\item 1 dedo: Orden: Avanzar, Parámetro:  Medio baja o 45º
\item 2 dedos: Orden: Girar derecha,  Parámetro:  Medio alta o 90º
\item 3 dedos: Orden: Girar Izquierda,  Parámetro:  Alta o 180º
\item  5 dedos: Orden: Parar ,  Parámetro:  Nula o 0º
\end{itemize} 
 
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.4,bb=0 0 160 120]{_orden_parada_17.png}
  \includegraphics[scale=0.4,bb=0 0 160 120]{_orden_avanza_38.png}
  \includegraphics[scale=0.4,bb=0 0 160 120]{_orden_angulo_43.png}
  \includegraphics[scale=0.4,bb=0 0 160 120]{_orden_negAngulo_84.png}
  \caption{ Ejemplos de imagenes de entrada en la red.}
\end{figure}

\section{Evolución}
El primer sistema utilizado para resolver el problema de reconocimiento de gestos, fue la implementación de dos redes distintas una para ordenes y otra para parámetros, debido a que su estructura era distinta.

Se fueron modificando los filtros con el objetivo de facilitar el aprendizaje a la red.

La segunda elección fue utilizar el mismo numero de gestos tanto en ordenes como en parámetros así se pudo conseguir la misma implementación para ambas.

Luego se redujo considerablemente el código, eliminando la parte de entrenamiento del proyecto. El código de entrenamiento pasaría a ser un programa a parte que generará archivos de redes entrenadas. En este punto había 2 archivos uno para cada red.

Y por ultimo visto que los gestos de las ordenes eran reconocidos con mucha mas facilidad que los asignados a los parámetros, que fallaban constantemente, decidimos que los gestos de los parámetros fuesen iguales a los de las ordenes, solo que en vez de hacer gestos con la izquierda se hacen con la derecha. De esta manera ambas redes cargan el mismo archivo y son igual de fiables. Solo se diferencian por la cadena de texto que devuelven, pero eso va por scripts.

\section{Código}
Ver anexo: documentación del módulo de red.c y red\_neuronal.c, en \ref {Codig_red} (página \pageref{Codig_red}).

