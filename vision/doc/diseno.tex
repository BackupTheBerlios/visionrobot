\section{Introducción}
En este capítulo vamos a dar una idea global de la arquitectura de \emph{Reconocimiento visual de instrucciones}. Tiene dos apartados importantes: la arquitectura modular, y la conexión de estos módulos.

\section {Arquitectura de la aplicación. Módulos en tubería}
Al diseñar la aplicación escogimos implementar un sistema altamente modular para conseguir un alto grado de independencia en el desarrollo y de fácil ampliación. Por esta razón hemos invertido parte del trabajo en desarrollar una plataforma propia de enlace de módulos, en la que la una parte de la aplicación (lo que hemos denominado {\em pipeline} o {\em tubería}), se encargue de realizar el trabajo mecánico, que, básicamente, se compone de:
\begin{itemize}
\item Conectar los módulos mediante puertos independientes con diferente información por puerto, pudiendo crear conexiones {\em 1 a 1}, {\em n a 1}, {\em 1 a n}, y {\em n a n}.
\item Iniciar y cerrar los módulos, creando y liberando la memoria necesaria y llamando a las funciones pertinentes de cada módulo.
\item Gestionar un reloj de ciclos de ejecución, transmitiendo la acción por el grafo que forma la arquitectura de módulos.
\item Control de proyectos de aplicación dinámicos, mediante definición de los mismos en {\bf XML}. De esta forma, diferentes archivos de configuración de proyecto puden crear aplicaciones totalmente distintas sin tener que reprogramar nada.
\item Manejo de errores mediante retrollamadas a funciones definidas por el usuario.
\end{itemize}
El {\em pipeline} es multiplataforma y funciona con módulos compilados desde {\em cualquier lenguaje estándar} como bibliotecas dinámicas. Esto dota a la aplicación de un marco muy amplio de uso en muchos ámbitos de desarrollo, no solamente el propio de la visión por computador o la robótica, sino en cualquier aplicación que necesite una arquitectura modular, ya sea secuencial o paralela.


\section{Diagrama de pipeline de ``Reconocimiento visual de instrucciones''}
En la figura \ref{diagrama_vision_computador} hemos esquematizado todo el proceso que siguen los datos de nuestra aplicación hasta llegar a una salida visible por el usuario. Los datos comienzan en la interfaz de imágenes (puede ser una imagen de cámara, un vídeo, una imagen fija...), y descienden por el grafo de módulos hasta el \textbf{robot} o el \textbf{entorno 3D}. Asimismo, tenemos también de entrada las ventanas de parámetros, que dotan a los filtros de los valores necesarios \emph{en tiempo real}.

Tras el filtrado pertinente de cada imagen, se las lleva a un módulo de proceso (redes neuronales para los guantes, y algoritmo de \emph{OCR} para el texto), y, paralelamente, a ventanas de visualización, para depuración y comprobación de resultados. Se filtran las señales erróneas y, para el módulo de texto, se envía la información a un módulo de DCG\footnote{Definite clause grammar} que genera una salida como respuesta ``inteligente''. Cuando la información ya ha sido extraída de cada imagen, sólo queda unificarla con el resto de datos, para dar una salida coherente.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.5]{pipeline.png}
  \caption{Diagrama de tubería}
  \label{diagrama_vision_computador}
\end{figure}
