\section{Trabajo futuro}

Dada la extensión del proyecto y que concierne a varios ámbitos de desarrollo, vamos a dividir esta sección según los apartados del mismo:

%% TODO: Que cada uno ponga aquí lo suyo. No nos extendamos. Está ahora liado, pero ya lo estableceremos mejor. No nos preocupemos por las secciones y eso.

\subsection{La aplicación y los módulos}
Los módulos de la aplicación son la parte más interesante del trabajo posterior al que puede dar lugar este proyecto. Cada uno es independiente de los demás, y sólo ``conocen'' entre sí las interfaces de entrada/salida que los definen. Por tanto, cualquiera de estos módulos puede ser incluido en un proyecto de visión por computador (en un principio, algunos módulos tienen una funcionalidad más general). Además, la aplicación que hemos creado puede sera ampliada añadiendo más módulos (para crear un sistema más inteligente, y enlazar esos nuevos módulos con la salida ya existente), o sustituyendo algunos, por ejemplo.

\subsection{Pipeline}

El pipeline consiste en una librería en C que conecta módulos y pasa información entre ellos. De este modo, sólo es necesario crear dichos módulos, conectarlos (escribiendo un archivo en \emph{XML}) y establecer sus argumentos (en el \emph{XML} también). Por tanto, esta pieza de código es perfectamente reusable en cualquier aplicación que necesite una arquitectura modular de elementos independientes que necesiten ser conectados entre sí. 
  
Por otro lado, podría tener interés la creación, como proyecto futuro, de un editor visual de dichos esquemas de conexión de módulos, que generase y leyese documentos en XML para el pipeline. Esto supondría una gran ventaja para la creación rápida de aplicaciones y la prueba \emph{in situ} de los proyectos.

Además, tendría gran utilidad una reimplemtación de la especificación del pipeline, de tal modo que la velocidad fuese mayor.

\subsection{Módulos}
Cada módulo es una caja negra que realiza una función de visión aumentado la capacidad de visión de la aplicación. Nosotros hemos desarrollado una serie de modulo capaces de reconocer gestos manuales o mensajes dentro de carteles.
\bigskip

Posibles proyectos futuros pueden realizar diversos módulos mejorando la interpretación visual del robot. Por ejemplo módulos que detecten:
\begin{itemize}
\item Zonas luminosas o tipo de absorción de la luz. 
\item Objetos móviles y tipo de movimiento.
\item Forma y volumen de objetos.
\item Textura y colores de superficies.
\item Etc.
\end{itemize} 

Cuanto mayor sea la capacidad de recoger características de la imagen de entrada, mayor será la capacidad de interpretación de esta por parte del robot. Si en un futuro se desarrollaran estos módulos, el robot sería capaz por ejemplo de detectar un objeto con una iluminación, un volumen, un color y textura determinada que coincidiría con la descripción que tiene almacenada de como es una \textit{mesa}. Sabría por tanto que dentro de la imagen existe una mesa, lo mismo pasaría con el resto de objetos del entorno. Sabiendo los objetos que existen en la imagen puede interpretar donde esta y como es el lugar.
\bigskip

Si en un futuro este proyecto sigue desarrollándose podría servir como descriptor automático de imágenes. O quizás como ayuda para invidentes.

\subsection{Robot}
Mediante la construcción del robot hemos demostrado la simpleza de la interacción entre software y hardware muy cercano al usuario. Los módulos y las rutinas que hemos desarrollado pueden servir bien como ejemplo o base para nuevos proyectos, o como módulos ya escritos que pueden ser usados mediante el \emph{pipeline}.

Una posible ampliación muy atractiva y visual sería añadir más funcionalidad al robot, ampliando el circuito y añadiendo motores, de forma que tuviese, por ejemplo, un brazo que pudiese coger cosas.

\subsection{Entorno 3D}

A continuación se enumeran una serie de ampliaciones y mejoras que se podrían introducir en el entorno 3d en futuras expansiones del proyecto:

\subsubsection{Detección de colisiones entre el robot y el entorno}
Se debería implementar un sistema para calcular en cada instante la posición del punto de contacto del robot con el terreno sobre el que se encuentra. De esta forma el robot podría navegar a través de entornos que contasen con suelos accidentados. Además de debería calcular posibles colisiones con distintos elementos como paredes, obstáculos y cualquier otro tipo de entidad física que se encuentre dentro de la simulación.

Para implementar la opción de que el robot se desplace sobre una superficie abrupta, se sugiere implementar un sistema que a partir de las coordenadas XZ del robot, se obtenga la correspondiente altura del terreno en ese punto, es decir la coordenada Y, la cual servirá para situar al robot a la altura adecuada. Este cálculo es trivial y consiste en una simple interpolación entre los vértices que componen el triángulo en cuyo interior se encuentra el punto XZ proyectado sobre el plano homónimo. Para realizar estos cálculos es necesario acceder a la información geométrica del terreno. Dicha información es accesible de una forma simple a través de la clase Terreno que se ha implementado.

En el caso de las colisiones con otros elementos del entorno lo más sencillo sería implementar un sistema de colisiones jerárquico. Este sistema consiste en ir realizando diferentes test de colisión que, de forma gradual, fueran refinando la precisión del cálculo de la colisión. De esta forma, se empezaría por realizar un test de colisión entre las bounding box (cajas imaginarias que engloban el volumen de una entidad 3d) del robot con los diferentes objetos estáticos del entorno. Si no existe colisión a este nivel, podemos asegurar que no hay colisión y por tanto terminar en este punto el cálculo. Si se produce colisión entre diferentes bounding box, debemos asegurarnos de que verdaderamente la geometría contenida en las cajas están en contacto. Para ello se pasaría a un segundo test de grano mucho más fino, en el que se realizarían comprobaciones de colisión entre los triángulos de cada una de las entidades 3d implicadas en la colisión. Este último cálculo suele ser bastante costos en cuanto a tiempo de computación, por eso es importante descartar en una primera pasada todas las situaciones que no requieran un cálculo tan preciso. De nuevo, la clase Objeto proporcionada, da acceso a todos los datos de la geometría necesarios para realizar estos cálculos. Además, el propio lenguaje gráfico empleado (Direct3D), proporciona a través de su librería auxiliar D3DX multitud de funciones que facilitan la implementación del sistema de colisiones aquí propuesto.

Añadiremos una última cuestión respecto al tema de las colisiones. Si se quisiera representar un entorno extremadamente complejo, con una gran cantidad de geometría 3d, sería necesario añadir un nivel más a la jerarquía de colisiones previamente expuesta. Sería adecuado realizar en primera instancia un test previo en el cuál se detectaría en que sector del escenario se encuentra el robot, pudiendo descartar en esta primera pasada todos aquellos elementos que se encontrarán fuera de dicho sector. Luego se pasaría a realizar el algoritmo ya explicado únicamente con los objetos que comparten sector con el robot. Para implementar este sistema, habría que crear una estructura de partición del entorno. Se pueden optar por distintas aproximaciones como el uso de árboles BSP, Octrees, Quadtrees, etc. Sobre estas estructuras existe multitud de documentación al ser algoritmos de uso común en computación gráfica.

\subsubsection{Creación de rutas de navegación}
Para demostrar la funcionalidad del sistema de visión por computador como sistema de control de un robot, se podrían establecer diferentes rutas en el entorno 3d, que el robot debe seguir guiado por el usuario. De esta forma, el usuario debería guiar al robot a lo largo de una serie de puntos de control o waypoints para completar un recorrido. Además se podría incrementar la dificultad de dicho reto imponiendo reglas como recorrer la ruta en un tiempo determinado o a una velocidad lineal o de giro mínima.

La implementación de esta ampliación sería trivial una vez implementado el sistema de colisiones previamente propuesto. Así, simplemente habría que disponer una serie de objetos que se corresponderían con los puntos de navegación e ir comprobando si el robot colisiona con ellos en el orden adecuado. Obviamente habría que inhibir cualquier respuesta motriz a dicha colisión, ya que estos objetos no debería impedir el movimiento del robot.

\subsubsection{Modificación de los modelos (Robot, Escenario o Terreno)}
Si se quiere cambiar el aspecto de la simulación, incorporando nuevos modelos para los objetos 3d, simplemente habría que convertir los nuevos modelos desde su formato origen (normalmente formatos de programas de modelado 3D como 3Dstudio o Maya) al formato .X que es el que se usa en la aplicación. Dicha conversión se puede realizar a partir de los plugins que incluye el SDK de DirectX. Para modificar el terreno, únicamente hay que crear un nuevo mapa de altura (en formato crudo o RAW) y utilizar la pequeña aplicación auxiliar desarrollada para generar terrenos que configura el tamaño y grado de desnivel de la geometría así como las diferentes capas de texturas que se usarán en función de la altura.

\subsubsection{Mejoras en el apartado gráfico}
Para incrementar el aspecto visual de la aplicación se pueden introducir en el futuro nuevos efectos gráficos. Por ejemplo, se podría introducir el uso de texturas HDR que optimicen el comportamiento visual de la iluminación y los reflejos de los objetos 3D. Se podría incluir también la novedosa técnica PRT(precomputed radiance transfer) que permite implementar la técnica de iluminación global por radiosidad en tiempo real (esta característica se ha incorporado a la nueva versión de DirectX aparecida en Abril de 2005). Por supuesto, el uso de shaders para desarrollar nuevos efectos sería también muy apropiado, teniendo en cuenta además lo fácil de su programación gracias a las facilidades de Direct3D para integrar esta tecnología.

Cualquier otro tipo de modificación será fácilmente implementada ya que el diseño de la aplicación y su modularidad permiten una sencilla integración de nuevos componentes. Para más detalles consultar el diseño en el Anexo correspondiente al Entorno 3D.


